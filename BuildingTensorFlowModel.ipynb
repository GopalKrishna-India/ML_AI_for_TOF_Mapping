{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GopalKrishna-India/ML_AI_for_TOF_Mapping/blob/main/BuildingTensorFlowModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eWcAWTHEEbV9"
      },
      "source": [
        "# Install the earth engine API, Google Cloud API and authenticate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4dNuOwZBFEn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 762
        },
        "outputId": "179f1705-725d-4f1f-eca8-eff102dc2c10"
      },
      "source": [
        "!pip install earthengine-api\n",
        "from google.colab import auth\n",
        "\n",
        "auth.authenticate_user()\n",
        "\n",
        "# Import the Earth Engine API and initialize it.\n",
        "import ee\n",
        "\n",
        "ee.Authenticate()\n",
        "ee.Initialize()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting earthengine-api\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/56/c2/d9365b63a1576ad45ff7956cb477d12f360ea7cb7afd277d749c40b1ccc3/earthengine-api-0.1.204.tar.gz (145kB)\n",
            "\r\u001b[K     |██▎                             | 10kB 13.7MB/s eta 0:00:01\r\u001b[K     |████▌                           | 20kB 3.3MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 30kB 4.6MB/s eta 0:00:01\r\u001b[K     |█████████                       | 40kB 3.0MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 51kB 3.6MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 61kB 4.3MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 71kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 81kB 5.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 92kB 6.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 102kB 4.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 112kB 4.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 122kB 4.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 133kB 4.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 143kB 4.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 153kB 4.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from earthengine-api) (0.16.0)\n",
            "Requirement already satisfied: google-cloud-storage in /usr/local/lib/python3.6/dist-packages (from earthengine-api) (1.16.2)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.6/dist-packages (from earthengine-api) (1.7.11)\n",
            "Requirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from earthengine-api) (1.4.2)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.6/dist-packages (from earthengine-api) (0.0.3)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.9.2 in /usr/local/lib/python3.6/dist-packages (from earthengine-api) (0.11.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from earthengine-api) (1.12.0)\n",
            "Requirement already satisfied: google-resumable-media<0.5.0dev,>=0.3.1 in /usr/local/lib/python3.6/dist-packages (from google-cloud-storage->earthengine-api) (0.4.1)\n",
            "Requirement already satisfied: google-cloud-core<2.0dev,>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from google-cloud-storage->earthengine-api) (1.0.3)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client->earthengine-api) (3.0.0)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->earthengine-api) (4.0)\n",
            "Requirement already satisfied: cachetools>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->earthengine-api) (3.1.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->earthengine-api) (0.2.7)\n",
            "Requirement already satisfied: google-api-core<2.0.0dev,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from google-cloud-core<2.0dev,>=1.0.0->google-cloud-storage->earthengine-api) (1.14.3)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa>=3.1.4->google-auth>=1.4.1->earthengine-api) (0.4.7)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2.0dev,>=1.0.0->google-cloud-storage->earthengine-api) (1.6.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2.0dev,>=1.0.0->google-cloud-storage->earthengine-api) (2018.9)\n",
            "Requirement already satisfied: setuptools>=34.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2.0dev,>=1.0.0->google-cloud-storage->earthengine-api) (41.4.0)\n",
            "Requirement already satisfied: protobuf>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2.0dev,>=1.0.0->google-cloud-storage->earthengine-api) (3.10.0)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2.0dev,>=1.0.0->google-cloud-storage->earthengine-api) (2.21.0)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2.0dev,>=1.0.0->google-cloud-storage->earthengine-api) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2.0dev,>=1.0.0->google-cloud-storage->earthengine-api) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2.0dev,>=1.0.0->google-cloud-storage->earthengine-api) (2019.9.11)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2.0dev,>=1.0.0->google-cloud-storage->earthengine-api) (2.8)\n",
            "Building wheels for collected packages: earthengine-api\n",
            "  Building wheel for earthengine-api (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for earthengine-api: filename=earthengine_api-0.1.204-cp36-none-any.whl size=175146 sha256=1a454567277fda277e6af3046082884e8f3c9fa13caf46edec2e3c63943e211d\n",
            "  Stored in directory: /root/.cache/pip/wheels/1c/84/12/072bd182af991b0f0b9c1599de80fa7b15179ba427106c5b17\n",
            "Successfully built earthengine-api\n",
            "Installing collected packages: earthengine-api\n",
            "Successfully installed earthengine-api-0.1.204\n",
            "To authorize access needed by Earth Engine, open the following URL in a web browser and follow the instructions. If the web browser does not start automatically, please manually browse the URL below.\n",
            "\n",
            "    https://accounts.google.com/o/oauth2/auth?client_id=517222506229-vsmmajv00ul0bs7p89v5m89qs8eb9359.apps.googleusercontent.com&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fearthengine+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdevstorage.full_control&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&response_type=code\n",
            "\n",
            "The authorization workflow will generate a code, which you should paste in the box below. \n",
            "Enter verification code: 4/sgEzhP7rHumIl7I9JWxsqy8M1rkNHeP_sPL5g8RDq-2BXgioRv4q630\n",
            "\n",
            "Successfully saved authorization token.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36rbK6IpFGGf"
      },
      "source": [
        "# Import the tensorflow library and import the training and testing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3puC_1feFCxH"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "tf.enable_eager_execution()\n",
        "print(tf.__version__)\n",
        "\n",
        "trainFilePath = 'gs://yourbucket/Hanoi/trainFile.tfrecord.gz'\n",
        "testFilePath = 'gs://yourbucket/Hanoi/testFile.tfrecord.gz'\n",
        "\n",
        "print('Found training file.' if tf.gfile.Exists(trainFilePath)\n",
        "    else 'No training file found.')\n",
        "\n",
        "# Create a dataset from the TFRecord file in Cloud Storage.\n",
        "trainDataset = tf.data.TFRecordDataset(trainFilePath, compression_type='GZIP')\n",
        "# Print the first record to check.\n",
        "print(iter(trainDataset).next())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKs1r1CxFiMo"
      },
      "source": [
        "# Set the label and feature names"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OeX_yuXhFic1"
      },
      "source": [
        "label = \"land_class\"\n",
        "\n",
        "featureNames = list(['cb','blue','green','red','re1','re2','re3','nir','re4','waterVapor','cirrus','swir1','swir2',\"ndvi\"])\n",
        "featureNames.append(label)\n",
        "\n",
        "l = len(featureNames)\n",
        "print(l)\n",
        "featureNames = sorted(featureNames)\n",
        "featureNames.append(label)\n",
        "\n",
        "# List of fixed-length features, all of which are float32.\n",
        "columns = [\n",
        "  tf.io.FixedLenFeature(shape=[1], dtype=tf.float32) for k in featureNames\n",
        "]\n",
        "\n",
        "# Dictionary with names as keys, features as values.\n",
        "featuresDict = dict(zip(featureNames, columns))\n",
        "\n",
        "print(featuresDict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xW2mPbjuF9-m"
      },
      "source": [
        "# Read a serialized example into the structure defined by featuresDict."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58tFgyLgF-_-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "f9740c27-6089-4453-c88c-d341e0a4e45f"
      },
      "source": [
        "def parse_tfrecord(example_proto):\n",
        "  \"\"\"The parsing function.\n",
        "\n",
        "  Read a serialized example into the structure defined by featuresDict.\n",
        "\n",
        "  Args:\n",
        "    example_proto: a serialized Example.\n",
        "\n",
        "  Returns:\n",
        "    A tuple of the predictors dictionary and the label, cast to an `int32`.\n",
        "  \"\"\"\n",
        "  parsed_features = tf.io.parse_single_example(example_proto, featuresDict)\n",
        "  labels = parsed_features.pop(label)\n",
        "  return parsed_features, tf.cast(labels, tf.int32)\n",
        "\n",
        "# Map the function over the dataset.\n",
        "parsedDataset = trainDataset.map(parse_tfrecord, num_parallel_calls=5)\n",
        "\n",
        "# Print the first parsed record to check.\n",
        "print(iter(parsedDataset).next())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "({'blue': <tf.Tensor: id=15005, shape=(1,), dtype=float32, numpy=array([0.1179], dtype=float32)>, 'cb': <tf.Tensor: id=15006, shape=(1,), dtype=float32, numpy=array([0.1476], dtype=float32)>, 'cirrus': <tf.Tensor: id=15007, shape=(1,), dtype=float32, numpy=array([0.0012], dtype=float32)>, 'green': <tf.Tensor: id=15008, shape=(1,), dtype=float32, numpy=array([0.0969], dtype=float32)>, 'ndvi': <tf.Tensor: id=15009, shape=(1,), dtype=float32, numpy=array([0.38778746], dtype=float32)>, 'nir': <tf.Tensor: id=15010, shape=(1,), dtype=float32, numpy=array([0.175], dtype=float32)>, 're1': <tf.Tensor: id=15011, shape=(1,), dtype=float32, numpy=array([0.1], dtype=float32)>, 're2': <tf.Tensor: id=15012, shape=(1,), dtype=float32, numpy=array([0.1391], dtype=float32)>, 're3': <tf.Tensor: id=15013, shape=(1,), dtype=float32, numpy=array([0.1529], dtype=float32)>, 're4': <tf.Tensor: id=15014, shape=(1,), dtype=float32, numpy=array([0.1648], dtype=float32)>, 'red': <tf.Tensor: id=15015, shape=(1,), dtype=float32, numpy=array([0.0772], dtype=float32)>, 'swir1': <tf.Tensor: id=15016, shape=(1,), dtype=float32, numpy=array([0.1357], dtype=float32)>, 'swir2': <tf.Tensor: id=15017, shape=(1,), dtype=float32, numpy=array([0.1142], dtype=float32)>, 'waterVapor': <tf.Tensor: id=15018, shape=(1,), dtype=float32, numpy=array([0.0634], dtype=float32)>}, <tf.Tensor: id=15019, shape=(1,), dtype=int32, numpy=array([0], dtype=int32)>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GrsVbMF_GNyh"
      },
      "source": [
        "# Build the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UzV9xH3QGOFU"
      },
      "source": [
        "from tensorflow import keras\n",
        "\n",
        "\n",
        "# How many classes there are in the model.\n",
        "nClasses = 5\n",
        "\n",
        "# Add features .\n",
        "inputDataset = parsedDataset #.map(addFeatures)\n",
        "\n",
        "# Keras requires inputs as a tuple.  Note that the inputs must be in the\n",
        "# right shape.  Also note that to use the categorical_crossentropy loss,\n",
        "# the label needs to be turned into a one-hot vector.\n",
        "def toTuple(dict, label):\n",
        "  #return tf.transpose(list(dict.values())), tf.one_hot(indices=label, depth=nClasses)\n",
        "  return (tf.expand_dims(tf.transpose(list(dict.values())), 1),\n",
        "          tf.expand_dims(tf.one_hot(indices=label, depth=nClasses), 1))\n",
        "\n",
        "# Repeat the input dataset as many times as necessary in batches.\n",
        "inputDataset = inputDataset.map(toTuple).shuffle(3000).batch(300).repeat()\n",
        "\n",
        "# Define the layers in the model.\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Input((None, None, l-1,)),\n",
        "  tf.keras.layers.Conv2D(512, (1, 1), activation=tf.nn.relu),\n",
        "  tf.keras.layers.Dropout(0.15),\n",
        "  tf.keras.layers.Conv2D(256, (1, 1), activation=tf.nn.relu),\n",
        "  tf.keras.layers.Dropout(0.15),\n",
        "  tf.keras.layers.Conv2D(nClasses, (1, 1), activation=tf.nn.softmax)\n",
        "])\n",
        "\n",
        "# Compile the model with the specified loss function.\n",
        "model.compile(optimizer=tf.train.AdamOptimizer(learning_rate=0.005),#'adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "# Fit the model to the training data.\n",
        "# Don't forget to specify `steps_per_epoch` when calling `fit` on a dataset.\n",
        "training = model.fit(x=inputDataset, epochs=100,steps_per_epoch=10)\n",
        "\n",
        "%pylab inline\n",
        "plot(training.history['loss'],'x--')\n",
        "plot(training.history['acc'], 'o--')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQqo38DeI403"
      },
      "source": [
        "# Do the data validation using the test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2taRrOn6I7Ry",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0623a468-bd00-41b4-aaa5-d1b60aa47067"
      },
      "source": [
        "testDataset = (\n",
        "  tf.data.TFRecordDataset(testFilePath, compression_type='GZIP')\n",
        "    .map(parse_tfrecord, num_parallel_calls=5)\n",
        "    .map(toTuple)\n",
        "    .batch(1)\n",
        ")\n",
        "\n",
        "model.evaluate(testDataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    151/Unknown - 2s 10ms/step - loss: 0.4941 - acc: 0.8146"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.49410629941916157, 0.81456953]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENi1OQZ6JCDm"
      },
      "source": [
        "# Save your model in your cloud bucket"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRHxuq3IJHNQ"
      },
      "source": [
        "outputBucket = \"yourbucket/Hanoi/\"\n",
        "MODEL_DIR = 'gs://' + outputBucket + '/model'\n",
        "tf.contrib.saved_model.save_keras_model(model, MODEL_DIR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFh0-34MJjG3"
      },
      "source": [
        "# Make your model readable for the earthEngine"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grSNIkxmha1b"
      },
      "source": [
        "from tensorflow.python.tools import saved_model_utils\n",
        "\n",
        "meta_graph_def = saved_model_utils.get_meta_graph_def(MODEL_DIR, 'serve')\n",
        "inputs = meta_graph_def.signature_def['serving_default'].inputs\n",
        "outputs = meta_graph_def.signature_def['serving_default'].outputs\n",
        "\n",
        "# Just get the first thing(s) from the serving signature def.  i.e. this\n",
        "# model only has a single input and a single output.\n",
        "input_name = None\n",
        "for k,v in inputs.items():\n",
        "  input_name = v.name\n",
        "  break\n",
        "\n",
        "output_name = None\n",
        "for k,v in outputs.items():\n",
        "  output_name = v.name\n",
        "  break\n",
        "\n",
        "# Make a dictionary that maps Earth Engine outputs and inputs to\n",
        "# AI Platform inputs and outputs, respectively.\n",
        "import json\n",
        "input_dict = \"'\" + json.dumps({input_name: \"array\"}) + \"'\"\n",
        "output_dict = \"'\" + json.dumps({output_name: label}) + \"'\"\n",
        "\n",
        "print(input_dict)\n",
        "print(output_dict)\n",
        "\n",
        "# Put the EEified model next to the trained model directory.\n",
        "EEIFIED_DIR = 'gs://' + outputBucket + '/eeified'\n",
        "PROJECT = 'servir-rlcms'\n",
        "\n",
        "#print(EEIFIED_DIR)\n",
        "# You need to set the project before using the model prepare command.\n",
        "!earthengine set_project {PROJECT}\n",
        "!earthengine model prepare --source_dir {MODEL_DIR} --dest_dir {EEIFIED_DIR} --input {input_dict} --output {output_dict}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bzeo0JluLXUw"
      },
      "source": [
        "# Push your model to the AI platform"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RY1gH6CsLZkZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "81d7ad44-1b25-47fd-98ce-ed3aa01ca968"
      },
      "source": [
        "import time\n",
        "MODEL_NAME = 'Hanoi'\n",
        "VERSION_NAME = 'v' + str(int(time.time()))\n",
        "print('Creating version: ' + VERSION_NAME)\n",
        "\n",
        "#!gcloud ai-platform models create {MODEL_NAME} --project {PROJECT}\n",
        "!gcloud ai-platform versions create {VERSION_NAME} \\\n",
        "  --project {PROJECT} \\\n",
        "  --model {MODEL_NAME} \\\n",
        "  --origin {EEIFIED_DIR} \\\n",
        "  --runtime-version=1.14 \\\n",
        "  --framework \"TENSORFLOW\" \\\n",
        "  --python-version=3.5"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Creating version: v1571915575\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}